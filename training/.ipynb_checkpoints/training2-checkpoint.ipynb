{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqeC_bP8ba5H"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = '/content/drive/MyDrive/archive1'  # Adjust if needed\n",
        "MODEL_SAVE_PATH = 'C:\\ismotica\\project_programing\\apple-disease-detection\\models'  # Where models will be saved\n"
      ],
      "metadata": {
        "id": "F8sq7VpPblH0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "EQlMx_A6bn3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 224\n",
        "CHANNELS = 3\n",
        "EPOCHS = 50\n"
      ],
      "metadata": {
        "id": "UVq2mA87bt8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    DATASET_PATH,\n",
        "    seed=123,\n",
        "    shuffle=True,\n",
        "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "class_names = dataset.class_names\n",
        "n_classes = len(class_names)\n",
        "print(class_names)\n"
      ],
      "metadata": {
        "id": "ZsOwCtJMbykB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
        "    assert (train_split + val_split + test_split) == 1\n",
        "    ds_size = len(ds)\n",
        "\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(shuffle_size, seed=123)\n",
        "\n",
        "    train_size = int(train_split * ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "\n",
        "    train_ds = ds.take(train_size)\n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    test_ds = ds.skip(train_size + val_size)\n",
        "\n",
        "    return train_ds, val_ds, test_ds\n",
        "\n",
        "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)\n"
      ],
      "metadata": {
        "id": "Ax5RVe2sb0oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resize_and_rescale = tf.keras.Sequential([\n",
        "    layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "Nu4WUqgjb2pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "base_model = MobileNetV2(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False  # Freeze base\n",
        "\n",
        "model = models.Sequential([\n",
        "    resize_and_rescale,\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(n_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "ow0H94Shb528"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "Ykx8D1mZb70F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(test_ds)\n",
        "print(\"Test Accuracy:\", scores[1])\n",
        "\n",
        "# Plot training history\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label=\"Train Acc\")\n",
        "plt.plot(val_acc, label=\"Val Acc\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label=\"Train Loss\")\n",
        "plt.plot(val_loss, label=\"Val Loss\")\n",
        "plt.title(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UIM4nhwdb-sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, image_tensor):\n",
        "    img_array = tf.expand_dims(image_tensor, 0)\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = class_names[np.argmax(predictions[0])]\n",
        "    confidence = round(100 * np.max(predictions[0]), 2)\n",
        "    return predicted_class, confidence\n"
      ],
      "metadata": {
        "id": "ng4svaB7cAiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
        "files = os.listdir(MODEL_SAVE_PATH)\n",
        "\n",
        "versions = [int(f.split('.')[0]) for f in files if f.endswith('.keras') and f.split('.')[0].isdigit()]\n",
        "model_version = max(versions + [0]) + 1\n",
        "\n",
        "model.save(f\"{MODEL_SAVE_PATH}/{model_version}.keras\")\n",
        "print(f\"âœ… Model saved as version {model_version}.keras\")\n"
      ],
      "metadata": {
        "id": "cCMEde53cBQh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}